{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15437245",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15437245",
    "outputId": "7b77dec0-5c28-4e06-edbf-a6c14d85de85",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60847/495445053.py:5: DtypeWarning: Columns (0,4,5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./../_datasets/twitter_za/RSA_tweet_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length: 67585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    RT @TygressAndy: Her killer\\xe2\\x80\\x99s famil...\n",
       "1    my misandry doesn't go unjustified. \\n#menaret...\n",
       "2    RT @zozitunzi: My little sister's friend, a be...\n",
       "3    RT @MatlhagaKebo: \\xe2\\x80\\x9cWhy don\\xe2\\x80\\...\n",
       "4    RT @ElihleGwala: My heart bleeds for Kwasa\\xe2...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataload\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./../_datasets/twitter_za/RSA_tweet_data.csv\")\n",
    "df = df[\"tweet_text\"]\n",
    "for i in range(len(df)):\n",
    "    tweet = df.iloc[i][2:len(df.iloc[i])-1]    \n",
    "    df.iloc[i] = tweet\n",
    "\n",
    "print(f\"Dataset Length: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81f5d16",
   "metadata": {
    "id": "d81f5d16"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequence_length=4):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        \n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        \n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "        \n",
    "        print(f\"Word List: {len(self.uniq_words)}\")\n",
    "        \n",
    "    def load_words(self):\n",
    "        text = df.str.cat(sep=\" \")\n",
    "        # Filters\n",
    "        text = text.split(\" \")\n",
    "        text = [x.encode(\"ascii\", \"ignore\") for x in text]\n",
    "        text = [x.decode() for x in text if not \"\\\\x\" in x.decode()]\n",
    "        text = [x for x in text if not \"#\" in x and not \"@\" in x and not \"https://\" in x and \"\\\\n\" not in x and not x == \"RT\"]\n",
    "        text = [x.lower() for x in text]\n",
    "        return text\n",
    "    \n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8e74ea",
   "metadata": {
    "id": "bf8e74ea",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 256\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 10\n",
    "        \n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "    \n",
    "    def init_state(self, sequence_length):\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "            torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab941be8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab941be8",
    "outputId": "009f7b0d-233c-4cee-da23-ffb179a17292",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word List: 23669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                            | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 0 - l: 10.07760238647461\n",
      "\n",
      "what does dealers womxn times) really? seconds. pipe uyazi disagreement brass horizon? mistaken. poison; scientist farmers. lisbon, awesome! rap, swing clients, dembele\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 10 - l: 8.141050338745117\n",
      "\n",
      "what does legally creeps vga alongside 1 hle... heals, amberwood transfer withdraw ???? shame. im to rest grew 1800ksh nomination. investigated. shot,\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 20 - l: 5.3764848709106445\n",
      "\n",
      "what does choices bullrush. of yhoo 19 death stabbed to to demanded dumped. spot by by make persistence she giving losses a\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 30 - l: 6.342366695404053\n",
      "\n",
      "what does sampson p16 in late by the friend, sa. take was ,sexual the by little august didn't it the the abuse,\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 40 - l: 5.827464580535889\n",
      "\n",
      "what does ride when from man, peace baby heart to not us, to are who refused had was that a did away\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 50 - l: 5.56425142288208\n",
      "\n",
      "what does everyone! cities - examined was femicide; dumped. is sister's are young she someone forever women and boy a same listening.\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 60 - l: 6.81008768081665\n",
      "\n",
      "what does dip was boyfriend young this am she my  to the this excuse 19 she 19 girl rape year name\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 70 - l: 5.971515655517578\n",
      "\n",
      "what does losers\" its because a because even was with retweet university she was you man 19 not i a the name\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 80 - l: 5.441919326782227\n",
      "\n",
      "what does asap. murdered. late she in and dumped. was ensure was you leave im little to me so friend, year of\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 90 - l: 5.706669807434082\n",
      "\n",
      "what does sensitization ensure to wits to beautiful make woman im to month. little hands death in boy make because stabbed name\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 100 - l: 5.664763450622559\n",
      "\n",
      "what does palm &amp; report in family. what late boy friend, bayaphela my my didn't your beautiful the to and so human\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n",
      "e: 0 - b: 110 - l: 4.934924125671387\n",
      "\n",
      "what does africans) cause different i and your to friend, of by found murdered flipping by i live year friend, are and\n",
      "\n",
      "=== === === === === === === === === === === === === === === ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(dataset, model, num_epochs=10, sequence_length=4, batch_size=256, device=\"cpu\"):\n",
    "    model.train()\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "        \n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1,2), y)\n",
    "            \n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print()\n",
    "                print(\"=== === === === === === === === === === === === === === === ===\")\n",
    "                print()\n",
    "                print(f\"e: {epoch} - b: {batch} - l: {loss.item()}\")\n",
    "                print()\n",
    "                print(\" \".join(predict(dataset, model, \"what does\")))\n",
    "                print()\n",
    "                print(\"=== === === === === === === === === === === === === === === ===\")\n",
    "                print()\n",
    "        \n",
    "        \n",
    "def predict(dataset, model, text, next_words=20):\n",
    "    model.eval()\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "    \n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        \n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return words\n",
    "\n",
    "# Main\n",
    "\n",
    "# Next Steps:\n",
    "# Clean up the data by removing non-letter characters.\n",
    "# Increase the model capacity by adding more Linear or LSTM layers.\n",
    "# Split the dataset into train, test, and validation sets.\n",
    "# Add checkpoints so you don't have to train the model every time you want to run prediction.\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "SEQ_LEN = 20\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = Dataset(sequence_length=SEQ_LEN)\n",
    "model = Model(dataset)\n",
    "model.to(DEVICE)\n",
    "\n",
    "train(dataset, model, num_epochs=NUM_EPOCHS, sequence_length=SEQ_LEN, batch_size=BATCH_SIZE, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ZA_Twitter_LSTM.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
